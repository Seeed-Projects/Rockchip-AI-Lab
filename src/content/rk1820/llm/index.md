# Large Language Models

Our research in Large Language Models focuses on optimizing and deploying advanced AI models on Rockchip hardware.

## Research Focus

### Model Optimization
We explore efficient inference techniques and model compression methods that leverage the capabilities of processors like RK3588 and RK1820.

### Hardware Acceleration
Our work focuses on maximizing the performance of LLMs on Rockchip's specialized AI processing units.

### Edge Deployment
We develop techniques for deploying LLMs on edge devices powered by Rockchip processors, enabling on-device AI capabilities.

## Hardware Integration

We explore efficient inference techniques and model compression methods that leverage the capabilities of processors like RK3588 and RK1820.

The RK3588's integrated NPU provides dedicated acceleration for AI workloads, making it suitable for running optimized LLMs.

The RK1820's focus on edge computing makes it ideal for lightweight LLM applications that require low power consumption.